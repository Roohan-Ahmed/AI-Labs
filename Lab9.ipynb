{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSikjS42A2eg",
        "outputId": "dfd6769a-5280-4f5b-b885-370af6a99c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: Rs. 26409.12\n",
            "RÂ²: 0.775\n",
            "Estimated House Cost: Rs. 434,842.98\n"
          ]
        }
      ],
      "source": [
        "#Task 1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "np.random.seed(123)\n",
        "n = 120\n",
        "\n",
        "area = np.random.normal(1600, 250, n).astype(int)\n",
        "rooms = np.random.randint(2, 6, n)\n",
        "toilets = np.random.randint(1, 4, n)\n",
        "property_age = np.random.randint(1, 40, n)\n",
        "zone = np.random.choice(['X', 'Y', 'Z'], n)\n",
        "\n",
        "cost = (\n",
        "    area * 180 +\n",
        "    rooms * 12000 +\n",
        "    toilets * 14000 -\n",
        "    property_age * 900 +\n",
        "    np.where(zone == 'Y', 30000, 0) +\n",
        "    np.where(zone == 'Z', 50000, 0) +\n",
        "    np.random.normal(0, 25000, n)\n",
        ").astype(int)\n",
        "\n",
        "housing_df = pd.DataFrame({\n",
        "    'area': area,\n",
        "    'rooms': rooms,\n",
        "    'toilets': toilets,\n",
        "    'property_age': property_age,\n",
        "    'zone': zone,\n",
        "    'cost': cost\n",
        "})\n",
        "\n",
        "df_encoded = pd.get_dummies(housing_df, columns=['zone'], drop_first=True)\n",
        "X = df_encoded.drop('cost', axis=1)\n",
        "y = df_encoded['cost']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=123)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predicted = model.predict(X_test)\n",
        "print(f\"RMSE: Rs. {np.sqrt(mean_squared_error(y_test, predicted)):.2f}\")\n",
        "print(f\"RÂ²: {r2_score(y_test, predicted):.3f}\")\n",
        "\n",
        "house_input = pd.DataFrame([{\n",
        "    'area': 1750,\n",
        "    'rooms': 4,\n",
        "    'toilets': 2,\n",
        "    'property_age': 5,\n",
        "    'zone_Y': 0,\n",
        "    'zone_Z': 1\n",
        "}])\n",
        "\n",
        "estimated_cost = model.predict(house_input)[0]\n",
        "print(f\"Estimated House Cost: Rs. {estimated_cost:,.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "emails_df = pd.DataFrame({\n",
        "    'content': [\n",
        "        \"Don't miss your chance to win a car now!\",\n",
        "        \"Team sync at 4pm today\",\n",
        "        \"Click this link to claim your bonus http://claim.com\",\n",
        "        \"Let's catch up next week\",\n",
        "        \"Cheap vacations await! http://scamholidays.com\",\n",
        "        \"Update your credentials here http://hackersite.com\",\n",
        "        \"Want to go for a walk?\",\n",
        "        \"Win $5,000 instantly! http://cashgrab.net\"\n",
        "    ],\n",
        "    'email_from': [\n",
        "        \"offer@dealz.com\", \"manager@corp.com\", \"promo@winnings.org\",\n",
        "        \"colleague@office.com\", \"agent@travelspree.com\",\n",
        "        \"alert@fraudulent.org\", \"buddy@mail.com\", \"jackpot@cashlottery.net\"\n",
        "    ],\n",
        "    'is_spam': [1, 0, 1, 0, 1, 1, 0, 1]\n",
        "})\n",
        "\n",
        "emails_df['msg_len'] = emails_df['content'].apply(len)\n",
        "emails_df['contains_link'] = emails_df['content'].str.contains(\"http\", case=False).astype(int)\n",
        "emails_df['sender_domain'] = emails_df['email_from'].apply(lambda x: x.split('@')[1])\n",
        "emails_df = pd.get_dummies(emails_df, columns=['sender_domain'], drop_first=True)\n",
        "\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "text_vectors = tfidf.fit_transform(emails_df['content'])\n",
        "\n",
        "features = emails_df.drop(['content', 'email_from', 'is_spam'], axis=1)\n",
        "X_full = hstack([text_vectors, features.astype(np.float64)])\n",
        "y_full = emails_df['is_spam']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.3, random_state=123)\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=123)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_preds = rf_model.predict(X_test)\n",
        "print(\"ðŸ“Š Classification Report:\")\n",
        "print(classification_report(y_test, y_preds))\n",
        "print(f\"âœ… Accuracy: {accuracy_score(y_test, y_preds):.2f}\")\n",
        "\n",
        "def check_spam(email_body, sender_email):\n",
        "    length = len(email_body)\n",
        "    link_flag = int(\"http\" in email_body.lower())\n",
        "    domain = sender_email.split(\"@\")[1]\n",
        "\n",
        "    body_vector = tfidf.transform([email_body])\n",
        "    sender_columns = [col for col in emails_df.columns if col.startswith(\"sender_domain_\")]\n",
        "\n",
        "    sender_vector = pd.DataFrame([{\n",
        "        f\"sender_domain_{domain}\": 1 if f\"sender_domain_{domain}\" in sender_columns else 0\n",
        "    }], columns=sender_columns).fillna(0)\n",
        "\n",
        "    meta = pd.DataFrame([{\n",
        "        'msg_len': length,\n",
        "        'contains_link': link_flag\n",
        "    }])\n",
        "\n",
        "    full_input = hstack([body_vector, pd.concat([meta, sender_vector], axis=1).astype(np.float64)])\n",
        "    prediction = rf_model.predict(full_input)[0]\n",
        "    return \"Spam\" if prediction == 1 else \"Not Spam\"\n",
        "\n",
        "sample_email = \"Let's meet at the cafe around 6?\"\n",
        "sample_sender = \"pal@friendsmail.com\"\n",
        "print(f\"ðŸ“§ Email classified as: {check_spam(sample_email, sample_sender)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXHL37JXA4IQ",
        "outputId": "d078be85-6492-4a83-d4df-56ae15060ed2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.50      0.25         3\n",
            "weighted avg       0.11      0.33      0.17         3\n",
            "\n",
            "âœ… Accuracy: 0.33\n",
            "ðŸ“§ Email classified as: Spam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "np.random.seed(42)\n",
        "n_customers = 300\n",
        "\n",
        "spending = np.random.normal(50000, 15000, n_customers).clip(10000, 100000)\n",
        "age = np.random.normal(40, 12, n_customers).clip(18, 80)\n",
        "visits = np.random.poisson(10, n_customers)\n",
        "frequency = np.random.uniform(0.2, 1.5, n_customers)\n",
        "\n",
        "labels = (spending > 60000) & (frequency > 0.8)\n",
        "labels = labels.astype(int)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'spending_6_months': spending,\n",
        "    'age': age,\n",
        "    'visits': visits,\n",
        "    'purchase_freq': frequency,\n",
        "    'is_high_value': labels\n",
        "})\n",
        "\n",
        "for col in ['spending_6_months', 'age']:\n",
        "    df.loc[df.sample(frac=0.05).index, col] = np.nan\n",
        "\n",
        "print(\"First 5 rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "\n",
        "df_imputed['spending_6_months'] = df_imputed['spending_6_months'].clip(10000, 100000)\n",
        "df_imputed['age'] = df_imputed['age'].clip(18, 80)\n",
        "\n",
        "features = ['spending_6_months', 'age', 'visits', 'purchase_freq']\n",
        "scaler = StandardScaler()\n",
        "df_imputed[features] = scaler.fit_transform(df_imputed[features])\n",
        "\n",
        "X = df_imputed[features]\n",
        "y = df_imputed['is_high_value']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "y_pred = svm.predict(X_test)\n",
        "\n",
        "print(\"\\n Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f\" Accuracy: {accuracy_score(y_test, y_pred):.2f}\")\n",
        "\n",
        "print(\"\\n Feature Importance (SVM Coefficients):\")\n",
        "for feature, weight in zip(features, svm.coef_[0]):\n",
        "    print(f\"{feature}: {weight:.4f}\")\n",
        "\n",
        "print(\"\\n Inferred Rules for Classification:\")\n",
        "for feature, weight in zip(features, svm.coef_[0]):\n",
        "    direction = \"â†‘\" if weight > 0 else \"â†“\"\n",
        "    impact = \"more likely HIGH-VALUE\" if weight > 0 else \"more likely LOW-VALUE\"\n",
        "    print(f\"{direction} {feature} â†’ {impact}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtc2xLbXBARQ",
        "outputId": "9c044bec-8429-4b26-e9f2-2dfc86b9dc21"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "   spending_6_months        age  visits  purchase_freq  is_high_value\n",
            "0       57450.712295  30.052060       7       0.972819              0\n",
            "1       47926.035482  33.277828      12       0.845797              0\n",
            "2       59715.328072  48.967523      12       1.484121              0\n",
            "3       72845.447846  47.324443       7       0.377372              0\n",
            "4       46487.699379        NaN       7       1.103688              0\n",
            "\n",
            " Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.96      0.94        77\n",
            "         1.0       0.70      0.54      0.61        13\n",
            "\n",
            "    accuracy                           0.90        90\n",
            "   macro avg       0.81      0.75      0.78        90\n",
            "weighted avg       0.89      0.90      0.89        90\n",
            "\n",
            " Accuracy: 0.90\n",
            "\n",
            " Feature Importance (SVM Coefficients):\n",
            "spending_6_months: 1.7775\n",
            "age: 0.0190\n",
            "visits: -0.3381\n",
            "purchase_freq: 1.3529\n",
            "\n",
            " Inferred Rules for Classification:\n",
            "â†‘ spending_6_months â†’ more likely HIGH-VALUE\n",
            "â†‘ age â†’ more likely HIGH-VALUE\n",
            "â†“ visits â†’ more likely LOW-VALUE\n",
            "â†‘ purchase_freq â†’ more likely HIGH-VALUE\n"
          ]
        }
      ]
    }
  ]
}